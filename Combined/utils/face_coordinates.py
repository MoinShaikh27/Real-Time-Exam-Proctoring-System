# -*- coding: utf-8 -*-
"""face_coordinates.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D-16Q6tEt5ONFSoyrHxJZkgF4eSWTRxP
"""

import cv2

# Load the Haarcascades classifiers for face and eye detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Open video capture for webcam (usually index 0)
cap = cv2.VideoCapture(0)

face_coordinates = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces
    # faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # # Clear the list for new frame
    # face_coordinates.clear()

    # for (x, y, w, h) in faces:
    #     # Draw rectangles around faces
    #     cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)

    #     # Save face coordinates in the list
    #     face_coordinates.append((x, y, x+w, y+h))

    #     # Detect eyes within the face region
    #     roi_gray = gray[y:y+h, x:x+w]

    cv2.imshow('Live Video', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# # Making static coordinates
# def student_coordinates(face_coordinates):
#     final_student_cd = []
#     for key,value in face_coordinates.items():
#         final_student_cd.append([value,key])
#     # return final_student_cd
#         make_master_dict(final_student_cd)

# # final_student_cd

# # creating Master dictionary
# def make_master_dict(coordinate):
#     master_dict = {}
#     for person in coordinate:
#         frame = cropped_frame(person[1])
#         face_obj = Face_detection(person[1])
#         head_mov = Head_movement(person[1])
#         master_dict[person[0]] = {"loc":person[1],
#                                   "frame":frame,
#                                   "face object":face_obj,
#                                   "head object":head_mov}
#     return master_dict

# for id,student in master_dict:
#     new_frame = get_frame()
#     c_frame = cropped_frame(new_frame)
#     student["frame"] = c_frame

"""### New processing from here"""

WAIT_PERIOD = 10
CHECK_FACES_IN_EVERY = 10

import cv2
import time

# Open video capture for webcam (usually index 0)
cap = cv2.VideoCapture(0)

while cap.isOpened():

    ret, frame = cap.read()

    if not ret:
        break


    # Now we have the initial frame

    # Wait for a certain period of time
    time.sleep(WAIT_PERIOD)

    # Now after the wait period start get the first frame and perform object detection
    list_of_coordinates = []

    # Call object detecion until atleast one person is detected
    while not list_of_coordinates:
        list_of_coordinates = call_object_detection(frame)

    # By now we would get the original coordinates of the people

    # Now call the extension module to get the extended location of all the people from the intial frame

    # Expected as a list of list
    list_of_extended_coordinates = extend_frames()

    master_dict = {}
    for coord in list_of_extended_coordinates:
        master_dict[str(uuid4())] = {"loc":coord,
        "cropped_frame": None,
        "eye_tracking_obj": EyeTracking(),
        "head_movement_obj": HeadMovement()
        }

    # Now perform the actual processing - within another infinite loop

    frame_count = 0

    while True:

        # Get a frame

        ret, per_process_frame = cap.read()

        if not ret:
            break

        # Now get the cropped frames from all the locations
        for obj_id, obj in master_dict.items():
            crop_location = obj["loc"]
            master_dict["cropped_frame"] = perform_crop(per_process_frame, crop_location)

            if frame_count == 0:

                # Firsr on this cropped frame perform the face detection, if a face is not available, error
                list_of_coordinates = call_object_detection(master_dict["cropped_frame"])

                if not list_of_coordinates:
                    # No person available in the prev corrdin - error
                    print("error")
                    continue


            head_response = master_dict["head_movement_obj"].process(master_dict["cropped_frame"])

            if head_response:
                # Some error based on head movement
                print("Error")
                continue

            else:
                eye_response = master_dict["eye_tracking_obj"].process(master_dict["cropped_frame"])

                if eye_response:
                    # Some error based on head movement
                    print("Error")
                    continue

        frame_count = (frame_count+1)%CHECK_FACES_IN_EVERY

import numpy as np
from uuid import uuid4

list_of_extended_coordinates = [np.random.randn(1, 4)[0].tolist() for ele in range(5)]

str(uuid4())

class EyeTracking:
    def __init__(self):
        pass

    def process(self, frame):
        return True

class HeadMovement:
    def __init__(self):
        pass

    def process(self, frame):
        return True



master_dict

