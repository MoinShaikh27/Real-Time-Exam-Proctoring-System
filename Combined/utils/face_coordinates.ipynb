{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the Haarcascades classifiers for face and eye detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open video capture for webcam (usually index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "face_coordinates = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    # faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # # Clear the list for new frame\n",
    "    # face_coordinates.clear()\n",
    "\n",
    "    # for (x, y, w, h) in faces:\n",
    "    #     # Draw rectangles around faces\n",
    "    #     cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "    #     # Save face coordinates in the list\n",
    "    #     face_coordinates.append((x, y, x+w, y+h))\n",
    "\n",
    "    #     # Detect eyes within the face region\n",
    "    #     roi_gray = gray[y:y+h, x:x+w]\n",
    "    \n",
    "    cv2.imshow('Live Video', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32cdcd04-d6fd-47c5-9e7f-9311c3e615f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making static coordinates\n",
    "# def student_coordinates(face_coordinates):\n",
    "#     final_student_cd = []\n",
    "#     for key,value in face_coordinates.items():\n",
    "#         final_student_cd.append([value,key])\n",
    "#     # return final_student_cd\n",
    "#         make_master_dict(final_student_cd)\n",
    "\n",
    "# # final_student_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ecd4264-c471-408a-b08b-48a52c4b977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating Master dictionary\n",
    "# def make_master_dict(coordinate):\n",
    "#     master_dict = {}\n",
    "#     for person in coordinate:\n",
    "#         frame = cropped_frame(person[1])\n",
    "#         face_obj = Face_detection(person[1])\n",
    "#         head_mov = Head_movement(person[1])\n",
    "#         master_dict[person[0]] = {\"loc\":person[1],\n",
    "#                                   \"frame\":frame,\n",
    "#                                   \"face object\":face_obj,\n",
    "#                                   \"head object\":head_mov}\n",
    "#     return master_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d6485-096b-41c2-8c1a-48710f329aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id,student in master_dict:\n",
    "#     new_frame = get_frame()\n",
    "#     c_frame = cropped_frame(new_frame) \n",
    "#     student[\"frame\"] = c_frame\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8ac62-afb0-4de8-8aee-99caa76f4773",
   "metadata": {},
   "source": [
    "### New processing from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "98e8bb62-fa21-4eb2-922d-21f489fcfaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAIT_PERIOD = 10\n",
    "CHECK_FACES_IN_EVERY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e631c98-9941-424d-9f1c-73f4e9c6015b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'call_object_detection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Call object detecion until atleast one person is detected\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m list_of_coordinates:\n\u001b[1;32m---> 25\u001b[0m     list_of_coordinates \u001b[38;5;241m=\u001b[39m \u001b[43mcall_object_detection\u001b[49m(frame)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# By now we would get the original coordinates of the people\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Now call the extension module to get the extended location of all the people from the intial frame\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Expected as a list of list\u001b[39;00m\n\u001b[0;32m     32\u001b[0m list_of_extended_coordinates \u001b[38;5;241m=\u001b[39m extend_frames()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'call_object_detection' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Open video capture for webcam (usually index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "\n",
    "    # Now we have the initial frame\n",
    "\n",
    "    # Wait for a certain period of time\n",
    "    time.sleep(WAIT_PERIOD)\n",
    "\n",
    "    # Now after the wait period start get the first frame and perform object detection\n",
    "    list_of_coordinates = []\n",
    "\n",
    "    # Call object detecion until atleast one person is detected\n",
    "    while not list_of_coordinates:\n",
    "        list_of_coordinates = call_object_detection(frame)\n",
    "\n",
    "    # By now we would get the original coordinates of the people\n",
    "\n",
    "    # Now call the extension module to get the extended location of all the people from the intial frame\n",
    "\n",
    "    # Expected as a list of list\n",
    "    list_of_extended_coordinates = extend_frames()\n",
    "\n",
    "    master_dict = {}\n",
    "    for coord in list_of_extended_coordinates:\n",
    "        master_dict[str(uuid4())] = {\"loc\":coord, \n",
    "        \"cropped_frame\": None,\n",
    "        \"eye_tracking_obj\": EyeTracking(),\n",
    "        \"head_movement_obj\": HeadMovement()\n",
    "        }\n",
    "\n",
    "    # Now perform the actual processing - within another infinite loop\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Get a frame\n",
    "    \n",
    "        ret, per_process_frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        # Now get the cropped frames from all the locations\n",
    "        for obj_id, obj in master_dict.items():\n",
    "            crop_location = obj[\"loc\"]\n",
    "            master_dict[\"cropped_frame\"] = perform_crop(per_process_frame, crop_location)\n",
    "\n",
    "            if frame_count == 0:\n",
    "    \n",
    "                # Firsr on this cropped frame perform the face detection, if a face is not available, error\n",
    "                list_of_coordinates = call_object_detection(master_dict[\"cropped_frame\"])\n",
    "        \n",
    "                if not list_of_coordinates:\n",
    "                    # No person available in the prev corrdin - error\n",
    "                    print(\"error\")\n",
    "                    continue\n",
    "    \n",
    "    \n",
    "            head_response = master_dict[\"head_movement_obj\"].process(master_dict[\"cropped_frame\"])\n",
    "    \n",
    "            if head_response:\n",
    "                # Some error based on head movement\n",
    "                print(\"Error\")\n",
    "                continue\n",
    "    \n",
    "            else:\n",
    "                eye_response = master_dict[\"eye_tracking_obj\"].process(master_dict[\"cropped_frame\"])\n",
    "    \n",
    "                if eye_response:\n",
    "                    # Some error based on head movement\n",
    "                    print(\"Error\")\n",
    "                    continue\n",
    "\n",
    "        frame_count = (frame_count+1)%CHECK_FACES_IN_EVERY\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d1ff1ff-49d6-4a84-9491-88beb9dc5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18fb167d-f972-4411-80f5-cac6f681b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_extended_coordinates = [np.random.randn(1, 4)[0].tolist() for ele in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec3dcdc8-d35b-46ef-bffb-18ca5d7bb292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1b438781-bc0c-43b1-93cc-3c325abcbaf2'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8fcfc5a9-c9f0-47ba-b937-b08b8551eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeTracking:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def process(self, frame):\n",
    "        return True\n",
    "\n",
    "class HeadMovement:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def process(self, frame):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b04932fd-5f9b-44b4-acf5-e956c8582782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c26db41-0bc2-4563-8e3f-ca27bc42b156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11a773e7-31e8-4da1-8bc1-6b9b70f36943': {'loc': [1.2581377434771392,\n",
       "   -0.42999538635880513,\n",
       "   -1.5234638611108635,\n",
       "   -0.8913102797957396],\n",
       "  'frame': None,\n",
       "  'eye_tracking_obj': <__main__.EyeTracking at 0x210336bcb10>,\n",
       "  'head_movement_obj': <__main__.HeadMovement at 0x210335342d0>},\n",
       " '61deb413-d273-44ab-954a-5bca3befe354': {'loc': [0.861285750429168,\n",
       "   -0.7969160591744464,\n",
       "   1.6131642078097057,\n",
       "   -0.5799253503910696],\n",
       "  'frame': None,\n",
       "  'eye_tracking_obj': <__main__.EyeTracking at 0x21033605250>,\n",
       "  'head_movement_obj': <__main__.HeadMovement at 0x2103348d6d0>},\n",
       " '0bcb3f8a-50ec-4ccf-9800-ed27a054836d': {'loc': [1.4776663629246178,\n",
       "   -0.10538536123035279,\n",
       "   0.8421317218895823,\n",
       "   0.7159383515976371],\n",
       "  'frame': None,\n",
       "  'eye_tracking_obj': <__main__.EyeTracking at 0x210336a83d0>,\n",
       "  'head_movement_obj': <__main__.HeadMovement at 0x210336abe90>},\n",
       " '77e15e28-2b8f-49c8-85ac-0ccb1baa9ec2': {'loc': [-0.1574620311141526,\n",
       "   0.8125823254380358,\n",
       "   -0.24692579090684058,\n",
       "   1.3513188478462035],\n",
       "  'frame': None,\n",
       "  'eye_tracking_obj': <__main__.EyeTracking at 0x21003e44f10>,\n",
       "  'head_movement_obj': <__main__.HeadMovement at 0x21003e3b250>},\n",
       " 'd1b792d0-d444-437e-9788-629f5a36a703': {'loc': [-0.41290548354486933,\n",
       "   1.2742729508658517,\n",
       "   0.2510931646642701,\n",
       "   -1.3247413656282552],\n",
       "  'frame': None,\n",
       "  'eye_tracking_obj': <__main__.EyeTracking at 0x21003e3bcd0>,\n",
       "  'head_movement_obj': <__main__.HeadMovement at 0x21003e3b5d0>}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06f0b0-4a80-4c87-9736-2d10d525ba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
